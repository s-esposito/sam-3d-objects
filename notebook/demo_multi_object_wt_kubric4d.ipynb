{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copyright (c) Meta Platforms, Inc. and affiliates."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import uuid\n",
                "import imageio\n",
                "import numpy as np\n",
                "import torch\n",
                "from IPython.display import Image as ImageDisplay\n",
                "from pytorch3d.transforms import Transform3d\n",
                "from pytorch3d.renderer import look_at_view_transform\n",
                "\n",
                "from inference import Inference, ready_gaussian_for_video_rendering, load_image, display_image, make_scene, render_video"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PATH = os.getcwd()\n",
                "TAG = \"hf\"\n",
                "config_path = f\"{PATH}/../checkpoints/{TAG}/pipeline.yaml\"\n",
                "inference = Inference(config_path, compile=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load input image to lift to 3D (multiple objects)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils import load_image, load_masks, create_gaussians_from_depth, render_frame, create_gaussians_object"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATASET_PATH = \"/mnt/lustre/work/geiger/gwb987/data/kubric4d\"\n",
                "SCENE_NAME = \"scn02719\"\n",
                "DATA_PATH = os.path.join(DATASET_PATH, SCENE_NAME)\n",
                "FRAMES_PATH = os.path.join(DATA_PATH, \"frames_p0_v0\")  # viewpoint 0\n",
                "\n",
                "# get all rgba_0000.png images in FRAMES_PATH\n",
                "IMAGE_NAMES = sorted([f for f in os.listdir(FRAMES_PATH) if f.startswith(\"rgba_\") and f.endswith(\".png\")])\n",
                "IMAGE_PATHS = [os.path.join(FRAMES_PATH, name) for name in IMAGE_NAMES]\n",
                "IMAGE_PATH = IMAGE_PATHS[0]\n",
                "image = load_image(IMAGE_PATH)\n",
                "# drop alpha channel\n",
                "image = image[..., :3]\n",
                "\n",
                "H, W, _ = image.shape\n",
                "\n",
                "# get all segmentation_0000.png masks in FRAMES_PATH\n",
                "MASK_NAMES = sorted([f for f in os.listdir(FRAMES_PATH) if f.startswith(\"segmentation_\") and f.endswith(\".png\")])\n",
                "MASK_PATHS = [os.path.join(FRAMES_PATH, name) for name in MASK_NAMES]\n",
                "MASK_PATH = MASK_PATHS[0]\n",
                "\n",
                "masks = load_masks(MASK_PATH)\n",
                "display_image(image, masks)\n",
                "\n",
                "print(f\"Image shape: {image.shape}, dtype: {image.dtype}, min: {image.min()}, max: {image.max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert depth map to point map using camera intrinsics\n",
                "# Note: fx and fy should correspond to focal lengths along x (width) and y (height)\n",
                "fx = float(W)  # focal length in x direction (width)\n",
                "fy = float(H)  # focal length in y direction (height)\n",
                "cx = W / 2.0  # principal point x (image center)\n",
                "cy = H / 2.0  # principal point y (image center)\n",
                "\n",
                "K_matrix = np.eye(3)\n",
                "K_matrix[0, 0] = fx\n",
                "K_matrix[1, 1] = fy\n",
                "K_matrix[0, 2] = cx\n",
                "K_matrix[1, 2] = cy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "using_moge = True\n",
                "\n",
                "if not using_moge:\n",
                "    \n",
                "    # Load depth maps\n",
                "    DEPTH_NAMES = sorted([f for f in os.listdir(FRAMES_PATH) if f.startswith(\"depth_\") and f.endswith(\".tiff\")])\n",
                "    DEPTH_PATHS = [os.path.join(FRAMES_PATH, name) for name in DEPTH_NAMES]\n",
                "    DEPTH_PATH = DEPTH_PATHS[0]\n",
                "    depth_map = load_image(DEPTH_PATH, to_uint8=False)\n",
                "\n",
                "    # normalize depth to max 1 meter\n",
                "    # depth_map = depth_map / depth_map.max()\n",
                "\n",
                "    print(f\"Using camera intrinsics: fx={fx}, fy={fy}, cx={cx}, cy={cy}\")\n",
                "    print(\"Radial depth map with shape:\", depth_map.shape, \"dtype:\", depth_map.dtype, \"min:\", depth_map.min(), \"max:\", depth_map.max())\n",
                "\n",
                "    from utils import radial_to_z_depth\n",
                "\n",
                "    # Convert radial depth to z-depth\n",
                "    depth_map_z = radial_to_z_depth(depth_map, fx, fy, cx, cy)\n",
                "    # depth_map_z = depth_map\n",
                "    print(f\"Converted radial depth map to z-depth map with shape: {depth_map_z.shape}, dtype: {depth_map_z.dtype}, min: {depth_map_z.min()}, max: {depth_map_z.max()}\")\n",
                "\n",
                "    # Generate 3D point cloud from z-depth\n",
                "    # Create pixel coordinate grids (u, v)\n",
                "    v_coords, u_coords = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n",
                "\n",
                "    # Convert to 3D coordinates using pinhole camera model\n",
                "    z = depth_map_z\n",
                "    x = (u_coords - cx) * z / fx\n",
                "    y = (v_coords - cy) * z / fy\n",
                "\n",
                "    points = np.stack((x, y, z), axis=-1)  # (H, W, 3)\n",
                "    pointmap = torch.from_numpy(points).float()  # (H, W, 3)\n",
                "    \n",
                "    print(f\"Generated pointmap with shape: {pointmap.shape}, min: {pointmap.min():.3f}, max: {pointmap.max():.3f}\")\n",
                "\n",
                "else:\n",
                "    \n",
                "    # Run MoGe depth model to get pointmap\n",
                "    # Access the depth model from the inference pipeline\n",
                "    depth_model = inference._pipeline.depth_model\n",
                "\n",
                "    # Prepare image for depth inference\n",
                "\n",
                "    loaded_image = inference._pipeline.image_to_float(image)\n",
                "    loaded_image = torch.from_numpy(loaded_image)\n",
                "    loaded_mask = loaded_image[..., -1]\n",
                "    loaded_image_rgb = loaded_image.permute(2, 0, 1).contiguous()[:3]\n",
                "\n",
                "    # Run depth inference\n",
                "    with torch.no_grad():\n",
                "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
                "            depth_output = depth_model(loaded_image_rgb)\n",
                "\n",
                "    # Extract pointmap and convert to PyTorch3D camera convention\n",
                "    pointmap = depth_output[\"pointmaps\"]\n",
                "    depth_map_z = depth_output[\"depth\"].cpu().numpy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract pointmap and convert to PyTorch3D camera convention\n",
                "\n",
                "# Camera convention transformation (R3 -> PyTorch3D)\n",
                "\n",
                "r3_to_p3d_R, r3_to_p3d_T = look_at_view_transform(\n",
                "    eye=np.array([[0, 0, -1]]),\n",
                "    at=np.array([[0, 0, 0]]),\n",
                "    up=np.array([[0, -1, 0]]),\n",
                "    device=pointmap.device,\n",
                ")\n",
                "\n",
                "camera_convention_transform = Transform3d(device=pointmap.device).rotate(r3_to_p3d_R)\n",
                "pointmap = camera_convention_transform.transform_points(pointmap)\n",
                "\n",
                "print(f\"Pointmap shape: {pointmap.shape}\")\n",
                "print(f\"Pointmap min: {pointmap.min()}, max: {pointmap.max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_path = \"gaussians.ply\"\n",
                "gaussians = create_gaussians_from_depth(\n",
                "    image=image,\n",
                "    depth=depth_map_z,\n",
                "    fx=fx,\n",
                "    fy=fy,\n",
                "    cx=cx,\n",
                "    cy=cy,\n",
                "    normalize_depth=False,\n",
                "    output_path=output_path,\n",
                ")\n",
                "\n",
                "# Render Gaussians\n",
                "c2w = torch.eye(4)\n",
                "\n",
                "# Create intrinsics matrix (3x3)\n",
                "K = torch.from_numpy(K_matrix).float()\n",
                "\n",
                "# Render the frame\n",
                "rendered_frame, rendered_alpha = render_frame(\n",
                "    gaussians, \n",
                "    c2w=c2w, \n",
                "    K=K, \n",
                "    w=W, \n",
                "    h=H\n",
                ")\n",
                "\n",
                "# Display the rendered frame alongside the original image\n",
                "import matplotlib.pyplot as plt\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
                "\n",
                "ax1.imshow(image)\n",
                "ax1.set_title('Original Image', fontsize=14)\n",
                "# ax1.axis('off')\n",
                "\n",
                "ax2.imshow(rendered_frame.cpu().numpy())\n",
                "ax2.set_title('Rendered from Gaussian Splats', fontsize=14)\n",
                "#   ax2.axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "# plt.savefig(\"rendered_gaussians.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize pointmap\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
                "\n",
                "# Assuming pointmap is a tensor of shape (H, W, 3)\n",
                "pointmap_np = pointmap.cpu().numpy()\n",
                "\n",
                "# Map position to RGB colors for visualization\n",
                "normed_x = (pointmap_np[..., 0] - pointmap_np[..., 0].min()) / (pointmap_np[..., 0].max() - pointmap_np[..., 0].min())\n",
                "normed_y = (pointmap_np[..., 1] - pointmap_np[..., 1].min()) / (pointmap_np[..., 1].max() - pointmap_np[..., 1].min())\n",
                "normed_z = (pointmap_np[..., 2] - pointmap_np[..., 2].min()) / (pointmap_np[..., 2].max() - pointmap_np[..., 2].min())\n",
                "color_map = np.stack([normed_x, normed_y, normed_z], axis=-1)\n",
                "\n",
                "# Create figure with subplots\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
                "\n",
                "# Visualize color encoding of pointmap\n",
                "ax1.imshow(color_map)\n",
                "ax1.set_title('Pointmap Color Visualization', fontsize=14)\n",
                "ax1.axis('off')\n",
                "\n",
                "# Visualize the depth (z-coordinate) with matching colorbar height\n",
                "im = ax2.imshow(pointmap_np[..., 2], cmap='plasma')\n",
                "ax2.set_title('Pointmap Depth Visualization', fontsize=14)\n",
                "ax2.axis('off')\n",
                "\n",
                "# Create colorbar with same height as the image\n",
                "divider = make_axes_locatable(ax2)\n",
                "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
                "plt.colorbar(im, cax=cax, label='Depth (Z-coordinate)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize 3D point cloud using Plotly (works in remote Jupyter notebooks)\n",
                "import plotly.graph_objects as go\n",
                "\n",
                "# Reshape pointmap to (N, 3) where N = H * W\n",
                "points_3d = pointmap_np.reshape(-1, 3)\n",
                "\n",
                "# Get colors from the original image (RGB values in range [0, 255])\n",
                "# image_rgb = image  # Convert to (H, W, 3)\n",
                "colors_rgb = image # (image_rgb * 255).astype(np.uint8)  # Convert to 0-255 range\n",
                "colors_flat = colors_rgb.reshape(-1, 3)\n",
                "\n",
                "# bgr to rgb\n",
                "# colors_flat = colors_flat[:, ::-1]\n",
                "\n",
                "# Optional: Downsample for better performance (every Nth point)\n",
                "max_nr_points = 100000  # Adjust this based on performance needs\n",
                "if points_3d.shape[0] > max_nr_points:\n",
                "    downsample_factor = points_3d.shape[0] // max_nr_points\n",
                "else:\n",
                "    downsample_factor = 100  # Adjust this to control point cloud density\n",
                "points_downsampled = points_3d[::downsample_factor]\n",
                "colors_downsampled = colors_flat[::downsample_factor]\n",
                "\n",
                "# # Filter outliers\n",
                "# valid_mask = np.linalg.norm(points_downsampled, axis=1) < 3.0\n",
                "# points_filtered = points_downsampled[valid_mask]\n",
                "# colors_filtered = colors_downsampled[valid_mask]\n",
                "points_filtered = points_downsampled\n",
                "colors_filtered = colors_downsampled\n",
                "\n",
                "print(f\"Original points: {len(points_3d):,}\")\n",
                "print(f\"Downsampled points: {len(points_downsampled):,}\")\n",
                "print(f\"Filtered points: {len(points_filtered):,}\")\n",
                "\n",
                "# Create RGB color strings for Plotly\n",
                "rgb_colors = [f'rgb({r},{g},{b})' for r, g, b in colors_filtered]\n",
                "\n",
                "# Create 3D scatter plot\n",
                "fig = go.Figure(data=[go.Scatter3d(\n",
                "    x=points_filtered[:, 0],\n",
                "    y=points_filtered[:, 1],\n",
                "    z=points_filtered[:, 2],\n",
                "    mode='markers',\n",
                "    marker=dict(\n",
                "        size=2,\n",
                "        color=rgb_colors,\n",
                "        opacity=0.8\n",
                "    ),\n",
                "    text=[f'({x:.2f}, {y:.2f}, {z:.2f})' for x, y, z in points_filtered],\n",
                "    hoverinfo='text'\n",
                ")])\n",
                "\n",
                "# Update layout for better visualization\n",
                "fig.update_layout(\n",
                "    title='3D Point Cloud from Depth',\n",
                "    scene=dict(\n",
                "        xaxis_title='X',\n",
                "        yaxis_title='Y',\n",
                "        zaxis_title='Z',\n",
                "        aspectmode='data',\n",
                "        camera=dict(\n",
                "            eye=dict(x=1.5, y=1.5, z=1.5)\n",
                "        )\n",
                "    ),\n",
                "    width=1000,\n",
                "    height=800,\n",
                "    margin=dict(l=0, r=0, t=40, b=0)\n",
                ")\n",
                "\n",
                "# Show interactive plot in notebook\n",
                "fig.show()\n",
                "\n",
                "print(\"\\nInteractive controls:\")\n",
                "print(\"- Click and drag to rotate\")\n",
                "print(\"- Scroll to zoom\")\n",
                "print(\"- Double-click to reset view\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Gaussian Splats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pass the pointmap to inference for all masks\n",
                "# The pointmap is shared across all objects in the same scene\n",
                "\n",
                "# time outputs for mask\n",
                "import time\n",
                "\n",
                "outputs = []\n",
                "for mask in masks:\n",
                "    start_time = time.time()\n",
                "    output = inference(image, mask, seed=42, pointmap=pointmap)\n",
                "    end_time = time.time()\n",
                "    print(f\"Inference time for mask: {end_time - start_time:.2f} seconds\")\n",
                "    outputs.append(output)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Gaussian Splat of the Scene"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scene_gs = make_scene(*outputs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize 3D point cloud using Plotly (works in remote Jupyter notebooks)\n",
                "import plotly.graph_objects as go\n",
                "\n",
                "# visualize means as point cloud\n",
                "gaussians_xyz = scene_gs.get_xyz  # (N, 3)\n",
                "gaussians_features = scene_gs.get_features.squeeze(1)  # (N, 3)\n",
                "print(f\"xyz shape: {gaussians_xyz.shape}, min: {gaussians_xyz.min()}, max: {gaussians_xyz.max()}\")\n",
                "print(f\"features shape: {gaussians_features.shape}, min: {gaussians_features.min()}, max: {gaussians_features.max()}\")\n",
                "\n",
                "def SH2RGB(sh):\n",
                "    C0 = 0.28209479177387814\n",
                "    rgb = sh * C0 + 0.5\n",
                "    return rgb\n",
                "\n",
                "# convert features to rgb (sh0)\n",
                "gaussians_rgb = SH2RGB(gaussians_features)\n",
                "# clip to [0, 1]\n",
                "gaussians_rgb = torch.clamp(gaussians_rgb, 0.0, 1.0)\n",
                "print(f\"rgb shape: {gaussians_rgb.shape}, min: {gaussians_rgb.min()}, max: {gaussians_rgb.max()}\")\n",
                "\n",
                "# Reshape pointmap to (N, 3) where N = H * W\n",
                "points_3d = gaussians_xyz.cpu().numpy()\n",
                "colors_flat = gaussians_rgb.cpu().numpy() * 255\n",
                "colors_flat = colors_flat.astype(np.uint8)\n",
                "\n",
                "# Optional: Downsample for better performance (every Nth point)\n",
                "max_nr_points = 100000  # Adjust this based on performance needs\n",
                "if points_3d.shape[0] > max_nr_points:\n",
                "    downsample_factor = points_3d.shape[0] // max_nr_points\n",
                "else:\n",
                "    downsample_factor = 100  # Adjust this to control point cloud density\n",
                "points_downsampled = points_3d[::downsample_factor]\n",
                "colors_downsampled = colors_flat[::downsample_factor]\n",
                "\n",
                "# Filter outliers\n",
                "points_filtered = points_downsampled\n",
                "colors_filtered = colors_downsampled\n",
                "\n",
                "print(f\"Original points: {len(points_3d):,}\")\n",
                "print(f\"Downsampled points: {len(points_downsampled):,}\")\n",
                "print(f\"Filtered points: {len(points_filtered):,}\")\n",
                "\n",
                "# Create RGB color strings for Plotly\n",
                "rgb_colors = [f'rgb({r},{g},{b})' for r, g, b in colors_filtered]\n",
                "\n",
                "# Create 3D scatter plot\n",
                "fig = go.Figure(data=[go.Scatter3d(\n",
                "    x=points_filtered[:, 0],\n",
                "    y=points_filtered[:, 1],\n",
                "    z=points_filtered[:, 2],\n",
                "    mode='markers',\n",
                "    marker=dict(\n",
                "        size=2,\n",
                "        color=rgb_colors,\n",
                "        opacity=0.8\n",
                "    ),\n",
                "    text=[f'({x:.2f}, {y:.2f}, {z:.2f})' for x, y, z in points_filtered],\n",
                "    hoverinfo='text'\n",
                ")])\n",
                "\n",
                "# Update layout for better visualization\n",
                "fig.update_layout(\n",
                "    title='Predicted 3D Point Cloud',\n",
                "    scene=dict(\n",
                "        xaxis_title='X',\n",
                "        yaxis_title='Y',\n",
                "        zaxis_title='Z',\n",
                "        aspectmode='data',\n",
                "        camera=dict(\n",
                "            eye=dict(x=1.5, y=1.5, z=1.5)\n",
                "        )\n",
                "    ),\n",
                "    width=1000,\n",
                "    height=800,\n",
                "    margin=dict(l=0, r=0, t=40, b=0)\n",
                ")\n",
                "\n",
                "# Show interactive plot in notebook\n",
                "fig.show()\n",
                "\n",
                "print(\"\\nInteractive controls:\")\n",
                "print(\"- Click and drag to rotate\")\n",
                "print(\"- Scroll to zoom\")\n",
                "print(\"- Double-click to reset view\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the denormalized xyz coordinates\n",
                "xyz_unnormalized = scene_gs.get_xyz  # This applies: xyz * aabb[3:] + aabb[:3]\n",
                "\n",
                "# Camera convention transformation (R3 -> PyTorch3D)\n",
                "\n",
                "r3_to_p3d_R, r3_to_p3d_T = look_at_view_transform(\n",
                "    eye=np.array([[0, 0, -1]]),\n",
                "    at=np.array([[0, 0, 0]]),\n",
                "    up=np.array([[0, -1, 0]]),\n",
                "    device=pointmap.device,\n",
                ")\n",
                "\n",
                "# inverse transform (PyTorch3D -> R3)\n",
                "p3d_to_r3_R = r3_to_p3d_R.transpose(1, 2)\n",
                "\n",
                "camera_convention_transform = Transform3d(device=scene_gs.get_xyz.device).rotate(p3d_to_r3_R)\n",
                "xyz = camera_convention_transform.transform_points(xyz_unnormalized)\n",
                "\n",
                "# create new Gaussians object\n",
                "\n",
                "new_scene_gs = create_gaussians_object(\n",
                "    xyz=xyz,\n",
                "    features=scene_gs.get_features,\n",
                "    scales=scene_gs.get_scaling,\n",
                "    rots=scene_gs.get_rotation,\n",
                "    opacities=scene_gs.get_opacity,\n",
                ")\n",
                "\n",
                "# export gaussian splatting (as point cloud)\n",
                "scene_gs.save_ply(f\"{PATH}/gaussians/kubric4d/{SCENE_NAME}.ply\")\n",
                "\n",
                "# Render from the original camera viewpoint\n",
                "\n",
                "# Alternative: use identity matrix (camera at origin looking along z-axis)\n",
                "c2w = torch.eye(4)\n",
                "\n",
                "# Create intrinsics matrix (3x3)\n",
                "K_matrix = np.eye(3)\n",
                "K_matrix[0, 0] = fx\n",
                "K_matrix[1, 1] = fy\n",
                "K_matrix[0, 2] = cx\n",
                "K_matrix[1, 2] = cy\n",
                "K = torch.from_numpy(K_matrix).float()\n",
                "\n",
                "# Render the frame\n",
                "rendered_frame, _ = render_frame(\n",
                "    new_scene_gs, \n",
                "    c2w=c2w, \n",
                "    K=K, \n",
                "    w=W, \n",
                "    h=H,\n",
                ")\n",
                "\n",
                "# Display the rendered frame alongside the original image\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
                "\n",
                "ax1.imshow(image)\n",
                "ax1.set_title('Original Image', fontsize=14)\n",
                "ax1.axis('off')\n",
                "\n",
                "ax2.imshow(rendered_frame.cpu().numpy())\n",
                "ax2.set_title('Rendered from Gaussian Splats', fontsize=14)\n",
                "ax2.axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# render video\n",
                "video_scene_gs = ready_gaussian_for_video_rendering(scene_gs)\n",
                "video = render_video(\n",
                "    video_scene_gs,\n",
                "    r=1,\n",
                "    fov=60,\n",
                "    resolution=512,\n",
                ")[\"color\"]\n",
                "\n",
                "# save video as gif\n",
                "imageio.mimsave(\n",
                "    os.path.join(f\"{PATH}/gaussians/kubric4d/{SCENE_NAME}.gif\"),\n",
                "    video,\n",
                "    format=\"GIF\",\n",
                "    duration=1000 / 30,  # default assuming 30fps from the input MP4\n",
                "    loop=0,  # 0 means loop indefinitely\n",
                ")\n",
                "\n",
                "# notebook display\n",
                "ImageDisplay(url=f\"gaussians/kubric4d/{SCENE_NAME}.gif?cache_invalidator={uuid.uuid4()}\",)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "sam3d-objects",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
